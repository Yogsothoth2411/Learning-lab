{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d247241d",
   "metadata": {},
   "source": [
    "## 1. 環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ada4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers datasets accelerate peft trl bitsandbytes pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df803f",
   "metadata": {},
   "source": [
    "## 2. 資料集載入 & 查看結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c353ddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['source', 'messages', 'num_turns'],\n",
      "        num_rows: 15806\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['source', 'messages', 'num_turns'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n",
      "Train samples: 15806\n",
      "Test samples: 200\n",
      "[{'content': 'Recommend a movie to watch.\\n', 'role': 'user'}, {'content': 'I would recommend the movie, \"The Shawshank Redemption\" which is a classic drama film starring Tim Robbins and Morgan Freeman. This film tells a powerful story about hope and resilience, as it follows the story of a young man who is wrongfully convicted of murder and sent to prison. Amidst the harsh realities of prison life, the protagonist forms a bond with a fellow inmate, and together they navigate the challenges of incarceration, while holding on to the hope of eventual freedom. This timeless movie is a must-watch for its moving performances, uplifting message, and unforgettable storytelling.', 'role': 'assistant'}, {'content': 'Describe the character development of Tim Robbins\\' character in \"The Shawshank Redemption\".', 'role': 'user'}, {'content': 'In \"The Shawshank Redemption\", Tim Robbins plays the character of Andy Dufresne, a banker who is wrongfully convicted of murdering his wife and her lover. Over the course of the film, we see a significant transformation in Andy\\'s character.\\n\\nAt the beginning of the movie, Andy is a quiet, reserved man who maintains his innocence but is largely passive in the face of his unjust conviction. He seems almost aloof, detached from the harsh reality of his situation. However, beneath this seemingly impassive exterior, Andy is a man of deep intelligence and inner strength.\\n\\nAs the story progresses, Andy begins to adapt to his new environment. He uses his banking skills to gain favor with the prison guards and the warden, providing them with financial advice and even helping them with tax evasion. This not only earns him certain privileges but also gives him a measure of protection within the prison walls.\\n\\nDespite the grim circumstances, Andy never loses hope. He befriends a fellow inmate, Red, and shares with him his dream of living a quiet life in Zihuatanejo, a small town on the Pacific coast of Mexico. This dream keeps him going and becomes a symbol of hope for other inmates as well.\\n\\nPerhaps the most significant development in Andy\\'s character comes towards the end of the film, when it is revealed that he has been digging a tunnel through his cell wall for the past 19 years. This act of defiance, carried out with nothing but a small rock hammer, is a testament to Andy\\'s resilience and determination. It also shows his cunning, as he manages to keep his plan a secret from everyone, including Red.\\n\\nIn the end, Andy\\'s character arc is one of hope, resilience, and redemption. Despite being placed in a situation that seems hopeless, he never gives up. He maintains his dignity, uses his intelligence to his advantage, and ultimately, manages to escape from Shawshank, proving his innocence in the process. His character serves as a powerful symbol of the human spirit\\'s ability to endure and overcome even the most challenging circumstances.', 'role': 'assistant'}, {'content': \"Explain the significance of the friendship between Andy and Red in shaping Andy's character development.\", 'role': 'user'}, {'content': 'The friendship between Andy Dufresne (Tim Robbins) and Ellis \"Red\" Redding (Morgan Freeman) is central to the narrative of \"The Shawshank Redemption\", and plays a significant role in shaping Andy\\'s character development.\\n\\nWhen Andy first arrives at Shawshank, he is a quiet, introverted man, largely keeping to himself. Red, who is the long-term inmate, takes an interest in him and they slowly develop a friendship. Red\\'s wisdom, street-smart attitude, and his ability to procure items become instrumental in Andy\\'s survival and eventual escape.\\n\\nRed is initially skeptical of Andy\\'s innocence and his hopeful outlook on life. However, as their friendship grows, Red becomes more receptive to Andy\\'s perspective. This friendship provides Andy with a confidant, a sounding board, and a supportive ally amidst the harsh realities of prison life. \\n\\nAndy\\'s influence on Red is equally profound. Andy\\'s unyielding hope and resilience slowly chip away at Red\\'s hardened cynicism. Andy shares his dreams of freedom and his plans for the future with Red, which initially seem unrealistic to Red, but over time, Andy\\'s unwavering belief in hope begins to influence Red\\'s outlook on life.\\n\\nIn many ways, their friendship is a beacon of hope and humanity in an otherwise oppressive environment. It\\'s through this friendship that Andy finds the strength to maintain his dignity, persevere, and ultimately, to engineer his daring escape. It\\'s also through this friendship that Red finds hope for redemption and a life beyond the prison walls.\\n\\nIn conclusion, the friendship between Andy and Red is a pivotal element in shaping Andy\\'s character development. It\\'s through this bond that Andy finds the strength to endure his unjust imprisonment and to hold onto hope, ultimately leading to his redemption.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 載入整個\n",
    "dataset_all = load_dataset(\"trl-lib/Capybara\")\n",
    "\n",
    "# 查看樣本數\n",
    "print(dataset_all)\n",
    "print(\"Train samples:\", len(dataset_all['train']))\n",
    "print(\"Test samples:\", len(dataset_all['test']))\n",
    "print(dataset_all['train'][0][\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6348aee",
   "metadata": {},
   "source": [
    "## 3. 模型載入與量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458bc131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True 表示可以使用 GPU\n",
    "print(torch.cuda.get_device_name(0))  # 顯示 GPU 名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb214ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642ed82544e54947ae26bb869e261e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# 模型 (量化為 4bit)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,      # 或 load_in_8bit=True\n",
    "    bnb_4bit_use_double_quant=True,  # optional: 提升 4-bit 精度\n",
    "    bnb_4bit_quant_type=\"nf4\",       # nf4 或 fp4\n",
    "    bnb_4bit_compute_dtype=torch.float16 # 計算用 dtype\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520129e6",
   "metadata": {},
   "source": [
    "## 4. PEFT 創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8e526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,               # rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\",\"v_proj\"],  # 根據模型架構選\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # 也可傳入 TaskType物件\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, config)\n",
    "peft_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a198a34",
   "metadata": {},
   "source": [
    "## 6. 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a632651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "    #-----模型輸出相關-----#\n",
    "    output_dir=\"./PEFT-Capybara-Chat-DEMO\",# 儲存資料夾\n",
    "    logging_steps=10,# 每格多少step打印log，記錄一次訓練日誌 (例如損失值、學習率)\n",
    "    save_strategy=\"steps\",# 存檔按照step\n",
    "    save_steps=50,# 每50個step 存一次檢查點\n",
    "    save_total_limit=2, # 限制檢查點的數量，只保留最新的 N 個。\n",
    "    report_to=\"none\", # 不使用任何報告工具 (如 Weights & Biases)，如果需要集成可以設為 \"wandb\" 等。\n",
    "\n",
    "    #-----模型訓練過程相關-----#\n",
    "    num_train_epochs=1,# 訓練的總 epoch 數。一個 epoch 代表模型看過整個訓練資料集一次。\n",
    "\n",
    "    #-----模型訓練優化器和學習率排程-----#\n",
    "    gradient_accumulation_steps=4, # 梯度累積步數。在不增加實際批次大小的情況下，模擬更大的批次。\n",
    "    per_device_train_batch_size=1,# 每個 GPU (或 CPU) 裝置的訓練批次大小。\n",
    "    per_device_eval_batch_size=1,\n",
    "    learning_rate=2e-4,# 小學習率\n",
    "    fp16=True,   # 如果 GPU 支援\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018ba277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    input_texts = []\n",
    "    labels = []\n",
    "\n",
    "    for messages in examples['messages']:\n",
    "        full_input = \"\"\n",
    "        full_label = \"\"\n",
    "        for msg in messages:\n",
    "            role = msg[\"role\"]\n",
    "            content = msg[\"content\"].strip()\n",
    "            if role == \"user\":\n",
    "                # user 文本只當作 prompt，不計算 loss\n",
    "                full_input += f\"User: {content}\\n\"\n",
    "                full_label += \"\\n\" * len(tokenizer(content)[\"input_ids\"])  # 占位，稍後會變 -100\n",
    "            else:  # assistant\n",
    "                # assistant 文本當作模型要預測的 target\n",
    "                full_input += f\"Assistant: {content}\\n\"\n",
    "                full_label += content\n",
    "\n",
    "        # tokenizer\n",
    "        tokenized_input = tokenizer(full_input, truncation=True, padding=\"max_length\", max_length=512)\n",
    "        tokenized_label = tokenizer(full_label, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "        # 將 user 部分 mask 掉\n",
    "        tokenized_label_ids = tokenized_label[\"input_ids\"]\n",
    "        # user 部分對應的位置改成 -100\n",
    "        for i, id in enumerate(tokenized_label_ids):\n",
    "            if id == tokenizer.pad_token_id:\n",
    "                tokenized_label_ids[i] = -100\n",
    "\n",
    "        input_texts.append(tokenized_input[\"input_ids\"])\n",
    "        labels.append(tokenized_label_ids)\n",
    "\n",
    "    return {\"input_ids\": input_texts, \"labels\": labels}\n",
    "\n",
    "# 對整個 DatasetDict 做 map\n",
    "tokenized_datasets = dataset_all.map(preprocess_function,batched=True)\n",
    "\n",
    "# 太大了，費時，拆小一點\n",
    "small_train_dataset = tokenized_datasets[\"train\"].select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba700ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e12b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be05fa55b4ab438fabf41ef06a4defd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 3:27:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>8.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.267400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>7.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.758100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>6.480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>6.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>6.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>6.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>6.608600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>6.388300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=7.43806851196289, metrics={'train_runtime': 12541.3081, 'train_samples_per_second': 0.04, 'train_steps_per_second': 0.01, 'total_flos': 1.1538033278976e+16, 'train_loss': 7.43806851196289, 'epoch': 1.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 開始訓練\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee16c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 兩個方法在這裡的儲存一樣是LoRA權重\n",
    "# 儲存模型權重：方法1 如果有會包含tokenizer\n",
    "output_path = \"./PEFT-Capybara-Chat-DEMO\"\n",
    "trainer.save_model(output_path)\n",
    "\n",
    "# 儲存模型權重：方法2 明確指定只存LoRA權重\n",
    "# peft_model.save_pretrained(\"./LoRA_weights\")\n",
    "# 使用時：必須和原始 base model 配合載入 (from_pretrained(base_model) + peft_model.load_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6299fd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- 清理環境 --- #\n",
      "GPU 記憶體已嘗試釋放。\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print(\"# --- 清理環境 --- #\")\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"GPU 記憶體已嘗試釋放。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83fbf33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 載入 LoRA 適配器並合併模型範例 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516130774e524bc097a66ed879254d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning-lab\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1566: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合併後的模型已儲存至./PEFT-Capybara-Chat-DEMO，現在可以像普通模型一樣載入和使用。\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from peft import PeftModel\n",
    "print(\"\\n--- 載入 LoRA 適配器並合併模型範例 ---\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 從保存的路徑載入 LoRA 適配器\n",
    "lora_model = PeftModel.from_pretrained(base_model, output_path)\n",
    "\n",
    "# 將 LoRA 適配器與基礎模型權重合併，生成一個可獨立部署的模型\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "# 儲存合併後的模型\n",
    "merged_model.save_pretrained(output_path)\n",
    "tokenizer.save_pretrained(output_path)\n",
    "print(f\"合併後的模型已儲存至{output_path}，現在可以像普通模型一樣載入和使用。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 gptq量化儲存\n",
    "# from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# model_path = \"./PEFT-Capybara-Chat-DEMO\"\n",
    "# quantized_path = \"./PEFT-Capybara-Chat-Final-GPTQ\"\n",
    "\n",
    "# quant_config = BaseQuantizeConfig(\n",
    "#     bits=4,                 # 量化精度\n",
    "#     group_size=128,         # 分組大小，影響效能/精度\n",
    "#     desc_act=False          # 是否描述激活量化\n",
    "# )\n",
    "\n",
    "# model = AutoGPTQForCausalLM.from_pretrained(model_path, quantize_config=quant_config)\n",
    "# model.quantize()  # 執行量化\n",
    "# model.save_quantized(quantized_path)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# tokenizer.save_pretrained(quantized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4913a2551849cb88703461cc76955e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "import evaluate\n",
    "\n",
    "# from vllm import LLM, SamplingParams # 如果可以用vllm加速，需要另外寫vllm的模型使用方式\n",
    "output_path = \"./PEFT-Capybara-Chat-DEMO\"\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # 運算用 FP16\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    output_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15817af",
   "metadata": {},
   "source": [
    "## 7. 測試evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48788e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vllm import LLM, SamplingParams # 使用vllm加速\n",
    "from tqdm import tqdm # 顯示進度條\n",
    "def generate_text(prompts, use_vllm=False, llm=None, pipeline_gen=None, params=None, batch_size=2):\n",
    "    \"\"\"\n",
    "    prompts: list[str] - 要生成的 prompt\n",
    "    use_vllm: bool - 是否使用 vLLM\n",
    "    llm: vLLM 的 LLM 物件\n",
    "    pipeline_gen: transformers pipeline 物件\n",
    "    params: vLLM 的 SamplingParams\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "\n",
    "    if use_vllm:\n",
    "        # vLLM 批次生成\n",
    "        vllm_outputs = llm.generate(prompts, sampling_params=params)\n",
    "        for o in vllm_outputs:\n",
    "            outputs.append(o.outputs[0].text)\n",
    "    else:\n",
    "        # pipeline 批次生成\n",
    "        for i in tqdm(range(0, len(prompts), batch_size), desc=\"Pipeline generating\"):\n",
    "            batch_prompts = prompts[i:i+batch_size]\n",
    "            batch_outputs = pipeline_gen(batch_prompts, max_new_tokens=100, num_return_sequences=1)\n",
    "            for out in batch_outputs:\n",
    "                if isinstance(out, list):\n",
    "                    outputs.append(out[0][\"generated_text\"])\n",
    "                else:\n",
    "                    outputs.append(out[\"generated_text\"])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d6d91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipeline generating: 100%|██████████| 100/100 [25:24<00:00, 15.24s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.7627729177474976, 0.7669517993927002, 0.8192554116249084, 0.8047548532485962, 0.7410728931427002, 0.7449355721473694, 0.7612544298171997, 0.7948060035705566, 0.8297368288040161, 0.7811315059661865, 0.7972325086593628, 0.7765320539474487, 0.7872973680496216, 0.78782057762146, 0.8110166192054749, 0.7990453839302063, 0.7958991527557373, 0.7907364368438721, 0.7838118672370911, 0.7934437990188599, 0.7906996011734009, 0.7878732681274414, 0.7747454643249512, 0.8038123846054077, 0.7497748732566833, 0.7994127869606018, 0.8053687810897827, 0.8393769264221191, 0.8172674179077148, 0.8269230127334595, 0.8217172622680664, 0.7775309681892395, 0.7664794921875, 0.7842079401016235, 0.7756956815719604, 0.7461564540863037, 0.7486515045166016, 0.7710837125778198, 0.8268269300460815, 0.809393048286438, 0.7930091619491577, 0.8056514263153076, 0.7912476062774658, 0.7804070115089417, 0.7884009480476379, 0.817781925201416, 0.7744842171669006, 0.8099175691604614, 0.8210277557373047, 0.8137956857681274, 0.7861539125442505, 0.8068336248397827, 0.7483313679695129, 0.8175832629203796, 0.7979636192321777, 0.7822940349578857, 0.8012560606002808, 0.7516173124313354, 0.7902902364730835, 0.7980122566223145, 0.795975387096405, 0.806749701499939, 0.8031284809112549, 0.8110300302505493, 0.7940727472305298, 0.6632986068725586, 0.8110769391059875, 0.7503206729888916, 0.8038529753684998, 0.7829391956329346, 0.7829588055610657, 0.8264368772506714, 0.8332886695861816, 0.7871429920196533, 0.793641984462738, 0.7976394891738892, 0.7770756483078003, 0.7842751145362854, 0.7487879991531372, 0.8033750057220459, 0.7602481842041016, 0.8052289485931396, 0.8098878264427185, 0.8026012182235718, 0.810024619102478, 0.7444930672645569, 0.7994692921638489, 0.8097269535064697, 0.8124619722366333, 0.7545941472053528, 0.8097761273384094, 0.7988048791885376, 0.7952833771705627, 0.7997400760650635, 0.7731634378433228, 0.8117812275886536, 0.8005692362785339, 0.7964802980422974, 0.763154923915863, 0.783769428730011, 0.7505927681922913, 0.8023053407669067, 0.792068600654602, 0.7782206535339355, 0.7752852439880371, 0.7969626784324646, 0.8007360696792603, 0.7769945859909058, 0.7938392162322998, 0.8028203248977661, 0.7624918222427368, 0.7796714901924133, 0.7835940718650818, 0.7967342138290405, 0.7444940209388733, 0.769677996635437, 0.8158811330795288, 0.8036808371543884, 0.7854506969451904, 0.6916845440864563, 0.7533391714096069, 0.7605019211769104, 0.7636328935623169, 0.8046197295188904, 0.8195761442184448, 0.8087190389633179, 0.7813573479652405, 0.7357693910598755, 0.7882341742515564, 0.805396318435669, 0.8028939962387085, 0.8076404333114624, 0.7898485064506531, 0.7819527387619019, 0.8105827569961548, 0.7763310670852661, 0.8117614984512329, 0.7668978571891785, 0.7768486142158508, 0.7891359329223633, 0.8001718521118164, 0.7961636185646057, 0.7952964305877686, 0.7889071702957153, 0.786324679851532, 0.7702510952949524, 0.8070472478866577, 0.7824147939682007, 0.7894785404205322, 0.8051151037216187, 0.7844449281692505, 0.7743776440620422, 0.8189339637756348, 0.7869678735733032, 0.8158819675445557, 0.7917852401733398, 0.791979193687439, 0.7928862571716309, 0.8042179942131042, 0.8179531097412109, 0.7839598655700684, 0.7876136302947998, 0.8168215751647949, 0.7866783142089844, 0.797106146812439, 0.7585776448249817, 0.7927337884902954, 0.8048278093338013, 0.8033649921417236, 0.7944502830505371, 0.7941215634346008, 0.8418682813644409, 0.7996813058853149, 0.7906544208526611, 0.8019248247146606, 0.8057188987731934, 0.7917797565460205, 0.8027511239051819, 0.7836695909500122, 0.7992308139801025, 0.7877283096313477, 0.7761303186416626, 0.7992576360702515, 0.7607670426368713, 0.7523797750473022, 0.7895062565803528, 0.7920234203338623, 0.7767673134803772, 0.775722086429596, 0.7194633483886719, 0.783252477645874, 0.7882962226867676, 0.7625094056129456, 0.7619431614875793, 0.8116910457611084, 0.8255294561386108, 0.7833415269851685, 0.8042209148406982, 0.8014568090438843, 0.7604974508285522], 'recall': [0.7743526697158813, 0.7812193632125854, 0.8284866213798523, 0.8119763731956482, 0.8908886909484863, 0.9110133647918701, 0.7907642126083374, 0.8013131618499756, 0.8228743076324463, 0.8134633302688599, 0.8348951935768127, 0.8036115765571594, 0.8222938776016235, 0.8326516151428223, 0.826728880405426, 0.8285626173019409, 0.8304291367530823, 0.8376426696777344, 0.8103685975074768, 0.8401366472244263, 0.8224687576293945, 0.8381965160369873, 0.811572790145874, 0.810294508934021, 0.9176698923110962, 0.8154135942459106, 0.8340025544166565, 0.7943223714828491, 0.7982233762741089, 0.8864682912826538, 0.8209545612335205, 0.7732425928115845, 0.7509648203849792, 0.7730257511138916, 0.8130428791046143, 0.8973625302314758, 0.7671741247177124, 0.7839952707290649, 0.8055899739265442, 0.8429811000823975, 0.8003280758857727, 0.8248106241226196, 0.8139671683311462, 0.8470942974090576, 0.8163105845451355, 0.8307397365570068, 0.7850980162620544, 0.8176074028015137, 0.8408442735671997, 0.8295759558677673, 0.81322181224823, 0.8284645080566406, 0.8668503761291504, 0.846382200717926, 0.8368822932243347, 0.8463687896728516, 0.8082489967346191, 0.7788593769073486, 0.8174453973770142, 0.8244038224220276, 0.8163686990737915, 0.8722362518310547, 0.8492956161499023, 0.7365890741348267, 0.8438735008239746, 0.8565142154693604, 0.8179835677146912, 0.9030777812004089, 0.8326235413551331, 0.8235604763031006, 0.8134700059890747, 0.8365069031715393, 0.8196414709091187, 0.8106640577316284, 0.7993243932723999, 0.7797585725784302, 0.8149176836013794, 0.8042091131210327, 0.9131556749343872, 0.8228554129600525, 0.7536289691925049, 0.8267991542816162, 0.842370867729187, 0.8305054306983948, 0.8285818696022034, 0.8342605829238892, 0.8196395635604858, 0.8433946967124939, 0.8425256013870239, 0.9112714529037476, 0.8320640325546265, 0.8367360830307007, 0.8214517831802368, 0.8024138808250427, 0.8258958458900452, 0.830250084400177, 0.8224378824234009, 0.8272432088851929, 0.8370755314826965, 0.8156561851501465, 0.774956226348877, 0.7825064659118652, 0.8000880479812622, 0.8116371035575867, 0.7925828695297241, 0.8401809930801392, 0.812479555606842, 0.8333727717399597, 0.8156340718269348, 0.8233089447021484, 0.7982465028762817, 0.8066890239715576, 0.8083322048187256, 0.8216325044631958, 0.88710618019104, 0.8117510080337524, 0.823655366897583, 0.8379181623458862, 0.8123044967651367, 0.915718674659729, 0.7367498874664307, 0.7628328800201416, 0.7707575559616089, 0.8244988918304443, 0.8674988150596619, 0.8001000881195068, 0.8047621250152588, 0.9129824638366699, 0.8164769411087036, 0.8194581270217896, 0.8380394577980042, 0.8427513241767883, 0.8142898082733154, 0.7671232223510742, 0.8367007970809937, 0.8358066082000732, 0.8413364887237549, 0.8043850660324097, 0.8267473578453064, 0.7693708539009094, 0.8275681734085083, 0.833625316619873, 0.8096327185630798, 0.7222631573677063, 0.8093817830085754, 0.8144886493682861, 0.8028215169906616, 0.8190338611602783, 0.821508526802063, 0.7829036712646484, 0.8249154686927795, 0.758309543132782, 0.8225021958351135, 0.7948290109634399, 0.8272978067398071, 0.7148424386978149, 0.8168407678604126, 0.8061443567276001, 0.8910961747169495, 0.8164663314819336, 0.7998251914978027, 0.8755876421928406, 0.8413988351821899, 0.8621307611465454, 0.7965528964996338, 0.7453252673149109, 0.7689194679260254, 0.82148277759552, 0.7816144227981567, 0.7963184118270874, 0.7545733451843262, 0.8209571838378906, 0.8322494029998779, 0.8086130619049072, 0.8277467489242554, 0.8023413419723511, 0.8398851156234741, 0.819010317325592, 0.8203283548355103, 0.842123806476593, 0.8130263090133667, 0.7552129030227661, 0.8162906169891357, 0.77852863073349, 0.9075675010681152, 0.8079624176025391, 0.8181215524673462, 0.8056169748306274, 0.8360332250595093, 0.8368565440177917, 0.8249208927154541, 0.8299979567527771, 0.792177677154541, 0.9127195477485657, 0.7728669047355652, 0.7162064909934998, 0.7812868356704712, 0.7999088764190674, 0.8226852416992188, 0.8235347270965576], 'f1': [0.7685192227363586, 0.7740197777748108, 0.8238452076911926, 0.8083494901657104, 0.8091042041778564, 0.819646418094635, 0.7757287621498108, 0.7980462908744812, 0.8262913227081299, 0.7969695925712585, 0.8156293034553528, 0.7898398041725159, 0.804415225982666, 0.8096159100532532, 0.8187973499298096, 0.8135362863540649, 0.8127976059913635, 0.813513994216919, 0.7968690395355225, 0.8161229491233826, 0.8062713742256165, 0.8122562170028687, 0.7927317023277283, 0.8070403933525085, 0.8252696990966797, 0.8073338866233826, 0.8194355964660645, 0.8162283897399902, 0.807633101940155, 0.8556609749794006, 0.8213357329368591, 0.7753808498382568, 0.7586427927017212, 0.778576672077179, 0.7939302921295166, 0.8148038983345032, 0.7577996253967285, 0.7774859070777893, 0.8160703182220459, 0.8258457183837891, 0.7966517806053162, 0.8151184320449829, 0.8024466037750244, 0.8123844265937805, 0.8021130561828613, 0.8242099285125732, 0.7797549366950989, 0.813744306564331, 0.8308178782463074, 0.8216100931167603, 0.7994588017463684, 0.8175060153007507, 0.803242564201355, 0.8317335247993469, 0.8169596791267395, 0.8130710124969482, 0.8047373294830322, 0.7649959325790405, 0.8036384582519531, 0.8109934329986572, 0.8060431480407715, 0.8382158875465393, 0.8255671262741089, 0.7720192074775696, 0.8182160258293152, 0.7476245760917664, 0.8145156502723694, 0.8196426033973694, 0.8179853558540344, 0.8027362823486328, 0.7979227900505066, 0.8314414024353027, 0.8264087438583374, 0.7987304329872131, 0.7964730858802795, 0.7885977029800415, 0.7955468893051147, 0.7941170334815979, 0.8228437304496765, 0.8129984736442566, 0.7569240927696228, 0.8158714771270752, 0.8258100152015686, 0.8163148760795593, 0.8191981315612793, 0.7868247032165527, 0.8094287514686584, 0.8262180089950562, 0.8272207379341125, 0.8255649209022522, 0.8207687735557556, 0.8173305988311768, 0.8081557750701904, 0.801074743270874, 0.798660159111023, 0.8209117650985718, 0.811356246471405, 0.8115703463554382, 0.7984079122543335, 0.7993950247764587, 0.7625799775123596, 0.792282223701477, 0.7960581183433533, 0.7945776581764221, 0.7838386297225952, 0.8180014491081238, 0.80656498670578, 0.804196834564209, 0.8045891523361206, 0.8129355311393738, 0.7799595594406128, 0.7929502129554749, 0.7957708835601807, 0.8089918494224548, 0.8095675706863403, 0.7901548743247986, 0.8197498321533203, 0.8204424977302551, 0.7986518740653992, 0.7880890369415283, 0.7449521422386169, 0.7616656422615051, 0.7671787142753601, 0.8144380450248718, 0.8428568243980408, 0.8043864369392395, 0.7928871512413025, 0.8148521780967712, 0.802107036113739, 0.8123664259910583, 0.8200903534889221, 0.8248223662376404, 0.8018829226493835, 0.7744669914245605, 0.8234347701072693, 0.8049717545509338, 0.8262844085693359, 0.7851943373680115, 0.8010216355323792, 0.7791280746459961, 0.8136394619941711, 0.8144639134407043, 0.802400529384613, 0.7541155815124512, 0.7976866364479065, 0.7917524576187134, 0.8049288392066956, 0.8003056645393372, 0.8051750659942627, 0.7938540577888489, 0.8041713237762451, 0.7662594318389893, 0.8207142353057861, 0.79087895154953, 0.8215502500534058, 0.751349151134491, 0.8042179346084595, 0.7994603514671326, 0.8454310297966003, 0.8172090649604797, 0.79181307554245, 0.8292739987373352, 0.8289280533790588, 0.8226780891418457, 0.7968294620513916, 0.7518930435180664, 0.7806450724601746, 0.8130699992179871, 0.7923404574394226, 0.7953832745552063, 0.7738425135612488, 0.8312812447547913, 0.815640389919281, 0.7995328903198242, 0.8146311640739441, 0.8040266036987305, 0.8151232600212097, 0.810799241065979, 0.8015800714492798, 0.8201168775558472, 0.8001774549484253, 0.7655287384986877, 0.8076843023300171, 0.769545316696167, 0.8227194547653198, 0.7986277937889099, 0.8048610091209412, 0.7909291386604309, 0.8047491908073425, 0.7737324237823486, 0.8035468459129333, 0.8086097240447998, 0.7770605087280273, 0.8305438756942749, 0.7918033599853516, 0.7669919729232788, 0.78231281042099, 0.8020591139793396, 0.8119323253631592, 0.7907617688179016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.57.1)'}\n"
     ]
    }
   ],
   "source": [
    "# 選擇評估指標\n",
    "metric = evaluate.load(\"bertscore\")  # 也可換成 \"rouge\", \"bleu\"\n",
    "\n",
    "prompts = []\n",
    "labels = []\n",
    "\n",
    "for example in tokenized_datasets['test']:\n",
    "    messages = example['messages']\n",
    "    user_prompt = \"\".join([m['content']+\"\\n\" for m in messages if m['role']=='user'])\n",
    "    label = next((m['content'] for m in reversed(messages) if m['role']=='assistant'), \"\")\n",
    "    \n",
    "    prompts.append(user_prompt.strip())\n",
    "    labels.append(label.strip())\n",
    "\n",
    "# 批次大小，可以依 GPU 記憶體調整\n",
    "batch_size = 2\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# 選擇生成方式\n",
    "use_vllm = False  # True 時切換到 vLLM\n",
    "outputs = generate_text(prompts, use_vllm=use_vllm, llm=None, pipeline_gen=generator, params=None,batch_size=2)\n",
    "\n",
    "predictions.extend(outputs)\n",
    "references.extend(labels)\n",
    "\n",
    "results = metric.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30389a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7891\n",
      "Recall:    0.8190\n",
      "F1:        0.8031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "precision_avg = np.mean(results['precision'])\n",
    "recall_avg = np.mean(results['recall'])\n",
    "f1_avg = np.mean(results['f1'])\n",
    "\n",
    "print(f\"Precision: {precision_avg:.4f}\")\n",
    "print(f\"Recall:    {recall_avg:.4f}\")\n",
    "print(f\"F1:        {f1_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c63bf3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- 清理環境 --- #\n",
      "GPU 記憶體已嘗試釋放。\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print(\"# --- 清理環境 --- #\")\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"GPU 記憶體已嘗試釋放。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learning-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
