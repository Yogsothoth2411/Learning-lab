{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c8cc75",
   "metadata": {},
   "source": [
    "# 階段 1：資料載入與前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33e2a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 130319\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 11873\n",
      "    })\n",
      "})\n",
      "{'id': '56be85543aeaaa14008c9063', 'title': 'Beyoncé', 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'question': 'When did Beyonce start becoming popular?', 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 直接載入 SQuAD 2.0 官方版本\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "# 檢查資料結構\n",
    "print(dataset)\n",
    "\n",
    "# 查看一筆樣本\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ddb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 定義資料模型\n",
    "class testdata(BaseModel):\n",
    "    id: str\n",
    "    title: str\n",
    "    context: str\n",
    "    question: str\n",
    "    answers: Optional[dict] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "# 先抽樣 4000 筆作為初步測試\n",
    "sample_data = dataset[\"train\"].shuffle(seed=42).select(range(4000))\n",
    "\n",
    "# 將資料轉換為 LangChain Document 格式\n",
    "train_docs = []\n",
    "qa_pairs = []\n",
    "for item in sample_data:\n",
    "    data = testdata(**item)\n",
    "    # 建立檢索文檔\n",
    "    doc = Document(\n",
    "        page_content=f\"Title: {data.title}\\nContext: {data.context}\", \n",
    "        metadata={\"id\": data.id}\n",
    "    )\n",
    "    train_docs.append(doc)\n",
    "\n",
    "    # 建立 QA 配對資料（供評估使用）\n",
    "    qa_pairs.append(\n",
    "            {\n",
    "                \"id\": data.id,\n",
    "                \"question\": data.question,\n",
    "                \"gold label\": data.answers\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3f532",
   "metadata": {},
   "source": [
    "# 階段 2：文本切分與嵌入 (FAISS index 構建)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 text splitter 切分 context\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 創建文本切分器，設定 chunk_size 和 chunk_overlap\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "docs = splitter.split_documents(train_docs)\n",
    "\n",
    "# 創建 FAISS 向量庫\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        )\n",
    "\n",
    "# 建立FAISS索引 傳入測試字串，取得模型的向量維度參數\n",
    "index = faiss.IndexFlatL2(len(embeddings_model.embed_query(\"test dim len\")))\n",
    "\n",
    "# 創建向量庫\n",
    "vector_store = FAISS(embedding_function=embeddings_model,\n",
    "                     index=index,\n",
    "                     docstore=InMemoryDocstore(),\n",
    "                     index_to_docstore_id={},)\n",
    "\n",
    "# 將切分後的文件加入向量庫\n",
    "vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18410a",
   "metadata": {},
   "source": [
    "# 階段 3：Retriever 創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from nltk.tokenize import word_tokenize\n",
    "import jieba\n",
    "import nltk\n",
    "# 下載 punkt_tab 資料包以支援 word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# 稀疏檢索器：BM25\n",
    "\n",
    "# 定義中文 tokenizer（輸入資料如果是中文時可用）（英文使用nltk-word_tokenize）\n",
    "def chinese_tokenizer(text: str):\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# 使用 tokenizer 創建 BM25 retriever，注意必須正確傳入分詞函數\n",
    "bm25_retriever = BM25Retriever.from_documents(docs, preprocess_func=word_tokenize, k = 10)\n",
    "\n",
    "# 稠密檢索器：FAISS\n",
    "faiss_retriever = vector_store.as_retriever(search_kwargs={\"k\":10},search_type=\"similarity\")\n",
    "\n",
    "# 混合檢索：Ensemble Retriever\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.2,0.8]  # 可調整權重比例\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d3510",
   "metadata": {},
   "source": [
    "### 載入llm 模型 與 創建 輸入改寫器、交叉比對重排序器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Model name:\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# huggingface_token:\n",
    "token = \"Your_HuggingFace_Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065823e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=False,\n",
    "    token=token,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#gpu 量化設定\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 或 load_in_8bit=True\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=False,\n",
    "    token=token,\n",
    ")\n",
    "\n",
    "generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.1,\n",
    "    repetition_penalty=1.1,\n",
    "    pad_token_id = tokenizer.eos_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# 將 HuggingFace pipeline 封裝為 LangChain LLM\n",
    "llm = HuggingFacePipeline(pipeline=generation_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cefdfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# 交叉比對重排序器\n",
    "reranker = HuggingFaceCrossEncoder(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# 交叉比對重排序器，取前3名\n",
    "compressor = CrossEncoderReranker(model=reranker, top_n=3)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=hybrid_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "469829b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# 建立問答鏈\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=compression_retriever,\n",
    "    chain_type=\"stuff\"  # or \"map_reduce\", \"refine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab4e49",
   "metadata": {},
   "source": [
    "# 階段 4：測試 Recall、Precision、MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93236019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Eval: {'recall@k': 0.9101727447216891, 'precision@k': 0.3869481765834993, 'mrr': 0.8611644273832373, 'evaluated_count': 2605}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "# 建立 evaluator\n",
    "def evaluate_retriever(\n",
    "    retriever,\n",
    "    qa_pairs: List[dict],\n",
    "    k: int = 3\n",
    "):\n",
    "    \"\"\"Evaluate retriever with metrics: Recall@k, Precision@k, MRR.\"\"\"\n",
    "    total = 0\n",
    "    sum_recall = 0.0\n",
    "    sum_precision = 0.0\n",
    "    sum_mrr = 0.0\n",
    "\n",
    "    for qa in qa_pairs:\n",
    "        q = qa[\"question\"]\n",
    "        ground_truths = qa[\"gold label\"][\"text\"]  # list[str]\n",
    "        if not ground_truths:\n",
    "            continue  \n",
    "\n",
    "        \n",
    "        docs = retriever.invoke(q)\n",
    "        \n",
    "        hits = []\n",
    "        for idx, doc in enumerate(docs):\n",
    "            text = doc.page_content.lower()\n",
    "            \n",
    "            for gt in ground_truths:\n",
    "                if gt.lower() in text:\n",
    "                    hits.append(idx + 1) \n",
    "                    break\n",
    "\n",
    "        total += 1\n",
    "        if hits:\n",
    "            # Recall@k\n",
    "            sum_recall += 1\n",
    "            # Precision@k\n",
    "            sum_precision += len(hits) / k\n",
    "            # MRR\n",
    "            sum_mrr += 1.0 / hits[0]\n",
    "        else:\n",
    "            # no hit\n",
    "            sum_recall += 0\n",
    "            sum_precision += 0\n",
    "            sum_mrr += 0\n",
    "\n",
    "    # aggregate\n",
    "    recall_at_k = sum_recall / total if total > 0 else 0\n",
    "    precision_at_k = sum_precision / total if total > 0 else 0\n",
    "    mrr = sum_mrr / total if total > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"recall@k\": recall_at_k,\n",
    "        \"precision@k\": precision_at_k,\n",
    "        \"mrr\": mrr,\n",
    "        \"evaluated_count\": total\n",
    "    }\n",
    "\n",
    "\n",
    "# 進行評估\n",
    "results = evaluate_retriever(compression_retriever, qa_pairs, k=3)\n",
    "print(\"Retriever Eval:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb9ef1",
   "metadata": {},
   "source": [
    "# 階段 5：Langchain evaluation 測試 BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca174d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee95dcdbe804d8fac9601f3816d3469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9800\n",
      "       is_correct\n",
      "count  150.000000\n",
      "mean     0.980000\n",
      "std      0.140469\n",
      "min      0.000000\n",
      "25%      1.000000\n",
      "50%      1.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "# 將 QA pair 轉成 HuggingFace Dataset\n",
    "hf_dataset = Dataset.from_list([\n",
    "    {\"id\": qa[\"id\"], \"question\": qa[\"question\"], \"answers\": qa[\"gold label\"][\"text\"]}\n",
    "    for qa in qa_pairs[:150]  # 先用前150筆測試\n",
    "])\n",
    "\n",
    "# 批量生成 + 評估\n",
    "def generate_and_eval(batch):\n",
    "    # 將 question 欄位轉成 chain 預期的 key\n",
    "    inputs = [{\"query\": q} for q in batch[\"question\"]]\n",
    "    # batch[\"question\"] 是 list[str]\n",
    "    \n",
    "    # 嘗試使用 batch（支援批量的 chain）\n",
    "    try:\n",
    "        results = qa_chain.batch(inputs)\n",
    "        batch[\"prediction\"] = [r[\"result\"] for r in results]\n",
    "    except AttributeError:\n",
    "        # 如果 chain 不支援 batch ，就回退單筆 invoke\n",
    "        batch[\"prediction\"] = [qa_chain.invoke(q) for q in batch[\"question\"]]\n",
    "\n",
    "    # 準備 evaluate 的輸入格式\n",
    "    examples = [\n",
    "        {\"query\": q, \"answer\": a}\n",
    "        for q, a in zip(batch[\"question\"], batch[\"answers\"])\n",
    "    ]\n",
    "    predictions = [{\"result\": p} for p in batch[\"prediction\"]]\n",
    "\n",
    "    # 執行官方的 evaluate（支援批次）\n",
    "    eval_results = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "    batch[\"eval\"] = eval_results\n",
    "    return batch\n",
    "\n",
    "# 使用 map 批量處理，batch_size 可調整\n",
    "hf_dataset = hf_dataset.map(generate_and_eval, batched=True, batch_size=2)\n",
    "\n",
    "# 轉成 DataFrame\n",
    "eval_col = hf_dataset[\"eval\"]\n",
    "all_results = []\n",
    "for e in eval_col:\n",
    "    if isinstance(e, list):\n",
    "        all_results.extend(e)\n",
    "    else:\n",
    "        all_results.append(e)\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# 解析每筆是否正確，建立新欄位\n",
    "df['is_correct'] = df['results'].apply(lambda x: 1 if 'CORRECT' in x else 0)\n",
    "\n",
    "# 計算 Accuracy\n",
    "accuracy = df['is_correct'].mean()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 若想看其他統計\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a90535",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_raw = hf_dataset[\"prediction\"]\n",
    "refs = hf_dataset[\"answers\"]\n",
    "print(\"Preds:\", preds_raw[:2])\n",
    "print(\"Refs:\", refs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9294a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore (F1 mean): 0.8220\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "# 取得生成與答案\n",
    "preds_raw = hf_dataset[\"prediction\"]\n",
    "refs = hf_dataset[\"answers\"]\n",
    "\n",
    "# preds_raw 是 list[dict]，我們只取出其中的 result 欄位\n",
    "preds = [p[\"result\"] if isinstance(p, dict) and \"result\" in p else str(p) for p in preds_raw]\n",
    "\n",
    "# squad 2.0 包含無答案情況\n",
    "\n",
    "# 攤平 references（取每筆中的第一個答案）\n",
    "flatten_refs = [r[0] if isinstance(r, list) and len(r) > 0 else \"\" for r in refs]\n",
    "\n",
    "# 判斷是否有答案\n",
    "has_answer = [r.strip() != \"\" for r in flatten_refs]\n",
    "\n",
    "# 分離有答案與無答案的預測與參考\n",
    "answerable_preds = [p for p, ha in zip(preds, has_answer) if ha]\n",
    "answerable_refs = [r for r, ha in zip(refs, has_answer) if ha]\n",
    "\n",
    "# BERTScore（需要 bert-score 套件）\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bert_result = bertscore.compute(predictions=answerable_preds, references=answerable_refs, lang=\"en\")\n",
    "bert_f1_mean = sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"])\n",
    "print(f\"BERTScore (F1 mean): {bert_f1_mean:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
